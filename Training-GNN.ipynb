{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fc16fd-aa1f-4a25-a02e-f32d1f075536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2+cu118'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLOBAL_SEED = 42\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTHONIOENCODING\"] = \"utf8\"\n",
    "os.environ['PYTHONHASHSEED'] = str(GLOBAL_SEED)\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random as np_rnd\n",
    "import random as rnd\n",
    "import shutil\n",
    "import gc\n",
    "import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "import pickle\n",
    "import sklearn as skl\n",
    "from sklearn import model_selection\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW, Adam, SparseAdam\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51363885-b25c-40a8-96a1-ffd44904ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import coalesce, is_undirected, to_undirected, sort_edge_index\n",
    "from torch_geometric.sampler import BaseSampler\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c54a7e1-d30a-412a-b2ad-71a77bacc318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    contentType_mapper = pd.Series([\"clicks\", \"carts\", \"orders\"], index=[0, 1, 2])\n",
    "    target_weight = (0.1, 0.3, 0.6)\n",
    "    \n",
    "    n_folds = 3\n",
    "    batch_size = 256\n",
    "    epochs = 70\n",
    "    early_stopping_rounds = 10\n",
    "    eta = 5e-4\n",
    "    weight_decay = 1e-4\n",
    "    max_grad_norm = 1e+2\n",
    "    embed_dim = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b8bdde1-3601-4570-914c-e7437e7e6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickleIO(obj, src, op=\"w\"):\n",
    "    if op==\"w\":\n",
    "        with open(src, op + \"b\") as f:\n",
    "            pickle.dump(obj, f)\n",
    "    elif op==\"r\":\n",
    "        with open(src, op + \"b\") as f:\n",
    "            tmp = pickle.load(f)\n",
    "        return tmp\n",
    "    else:\n",
    "        print(\"unknown operation\")\n",
    "        return obj\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # python random\n",
    "    rnd.seed(seed)\n",
    "    # numpy random\n",
    "    np_rnd.seed(seed)\n",
    "    # RAPIDS random\n",
    "    try:\n",
    "        cp.random.seed(seed)\n",
    "    except:\n",
    "        pass\n",
    "    # tf random\n",
    "    try:\n",
    "        tf_rnd.set_seed(seed)\n",
    "    except:\n",
    "        pass\n",
    "    # pytorch random\n",
    "    try:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32a1e2a-c807-4013-90c7-4b4b2ff71745",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature = pickleIO(None, \"node_feature.pkl\", \"r\")\n",
    "node_feature = node_feature.to(device)\n",
    "n_aids = node_feature.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3283a82-1836-4ec2-a31a-8f27952290ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything()\n",
    "\n",
    "edge_index = torch.tensor(pd.read_parquet(\"train_edge.parquet\").values, dtype=torch.int64).T\n",
    "shuffled_idx = torch.randperm(edge_index.shape[1])\n",
    "edge_train = edge_index[:, shuffled_idx[: ((512 * 10000) * 1)]]\n",
    "pickleIO(edge_train, \"sampled_edge_train.pkl\", \"w\")\n",
    "edge_train = edge_train.to(device)\n",
    "\n",
    "edge_index = torch.tensor(pd.read_parquet(\"valid_edge.parquet\").values, dtype=torch.int64).T\n",
    "shuffled_idx = torch.randperm(edge_index.shape[1])\n",
    "edge_valid = edge_index[:, shuffled_idx[: ((512 * 2000) * 1)]]\n",
    "pickleIO(edge_valid, \"sampled_edge_valid.pkl\", \"w\")\n",
    "edge_valid = edge_valid.to(device)\n",
    "\n",
    "del edge_index, shuffled_idx\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d311d0-ff5b-41fa-9e40-4cc9232c517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_params(model, eta, weight_decay):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        # áp dụng weight decay\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'lr': eta, 'weight_decay': weight_decay},\n",
    "        # không áp dụng với tầng chuẩn hóa/bias\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "         'lr': eta, 'weight_decay': 0.0},\n",
    "    ]\n",
    "    return optimizer_parameters\n",
    "\n",
    "def get_scheduler(optimizer, num_warmup_steps, num_training_steps, power=0.5):\n",
    "    scheduler = get_polynomial_decay_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps, power=power, lr_end=1e-7\n",
    "    )\n",
    "    return scheduler\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b5c2cc6-5227-4e52-b5fd-b5b2ece0fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, n_aids, embed_dim):\n",
    "        super().__init__()\n",
    "        self.aid_factors = nn.Embedding(n_aids, embed_dim, sparse=False)\n",
    "        self.gcn = GCNConv(embed_dim, embed_dim)\n",
    "        self.gcn_act = nn.ReLU()\n",
    "        self.lin = nn.Linear(embed_dim, embed_dim)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.aid_factors(x)\n",
    "        x = self.gcn(x, edge_index=edge_index)\n",
    "        x = self.gcn_act(x)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fac21aa-ec37-49e2-b688-e172610ae787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(fold, model, criterion, optimizer, scheduler, grad_scaler):\n",
    "    model.train()\n",
    "    metrics = {\n",
    "        \"loss\": AverageMeter(),\n",
    "        \"accuracy\": AverageMeter(),\n",
    "    }\n",
    "    \n",
    "    with torch.cuda.amp.autocast():\n",
    "        # Lấy embedding\n",
    "        output = model(node_feature, edge_train)\n",
    "        # Tính loss và accuracy\n",
    "        output_neg = (output[edge_train[0]] * output[edge_train[1]][torch.randperm(len(edge_train[1]))]).sum(dim=-1)\n",
    "        output_pos = (output[edge_train[0]] * output[edge_train[1]]).sum(dim=-1)\n",
    "        loss = criterion(torch.cat([output_pos, output_neg]), torch.cat([torch.ones_like(output_pos), torch.zeros_like(output_neg)]))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    grad_scaler.scale(loss).backward()\n",
    "    grad_scaler.step(optimizer)\n",
    "    grad_scaler.update()\n",
    "    scheduler.step()\n",
    "\n",
    "    metrics[\"loss\"].update(loss.item())\n",
    "    metrics[\"accuracy\"].update(torch.cat([output_pos.flatten().sigmoid() >= 0.5, output_neg.flatten().sigmoid() < 0.5]).float().mean().item())        \n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def valid_fn(fold, model, criterion):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    metrics = {\n",
    "        \"loss\": AverageMeter(),\n",
    "        \"accuracy\": AverageMeter(),\n",
    "    }   \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(node_feature, edge_train)\n",
    "        output_neg = (output[edge_valid[0]] * output[edge_valid[1]][torch.randperm(len(edge_valid[1]))]).sum(dim=-1)\n",
    "        output_pos = (output[edge_valid[0]] * output[edge_valid[1]]).sum(dim=-1)\n",
    "        loss = criterion(torch.cat([output_pos, output_neg]), torch.cat([torch.ones_like(output_pos), torch.zeros_like(output_neg)]))\n",
    "\n",
    "    metrics[\"loss\"].update(loss.item())\n",
    "    metrics[\"accuracy\"].update(torch.cat([output_pos.flatten().sigmoid() >= 0.5, output_neg.flatten().sigmoid() < 0.5]).float().mean().item())        \n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def infer_fn(data, model, force_to_cpu=True):\n",
    "    model.to(\"cpu\") if force_to_cpu else model.to(device)\n",
    "    model.eval()\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        predictions = model(data.x, data.edge_index)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def do_fold_training(fold):\n",
    "    seed_everything(fold)\n",
    "    model = GCN(n_aids=n_aids, embed_dim=CFG.embed_dim).to(device)\n",
    "    optimizer_parameters = get_optimizer_params(\n",
    "        model,\n",
    "        eta=CFG.eta,\n",
    "        weight_decay=CFG.weight_decay\n",
    "    )\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.eta, weight_decay=CFG.weight_decay)\n",
    "    scheduler = get_scheduler(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=CFG.epochs\n",
    "    )\n",
    "    grad_scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "    best_score = np.inf\n",
    "    \n",
    "    early_stopping_cnt = 0\n",
    "    for epoch in range(CFG.epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        train_metrics = train_fn(fold, model, criterion, optimizer, scheduler, grad_scaler)\n",
    "        valid_metrics = valid_fn(fold, model, criterion)\n",
    "\n",
    "        score = valid_metrics[\"loss\"].avg\n",
    "        print(\"Epoch[{0}/{1}]\\n train loss : {2}\\n valid loss : {3}\\n train accuracy : {4}\\n valid accuracy : {5}\\n eta : {6}\\n Elapsed : {7}\\n\"\n",
    "              .format(\n",
    "                  epoch+1, CFG.epochs,\n",
    "                  round(train_metrics[\"loss\"].avg, 5), round(valid_metrics[\"loss\"].avg, 5),\n",
    "                  round(train_metrics[\"accuracy\"].avg, 5), round(valid_metrics[\"accuracy\"].avg, 5),\n",
    "                  round(scheduler.get_lr()[0], 5), round(time.time() - epoch_start_time, 3)\n",
    "              )\n",
    "        )\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            return_score_dic = {\n",
    "                \"fold\": fold,\n",
    "                \"train_loss\": train_metrics[\"loss\"].avg,\n",
    "                \"valid_loss\": valid_metrics[\"loss\"].avg,\n",
    "                \"train_accuracy\": train_metrics[\"accuracy\"].avg,\n",
    "                \"valid_accuracy\": valid_metrics[\"accuracy\"].avg,\n",
    "            }\n",
    "            model_save_dic = {'model': model.state_dict()}\n",
    "            early_stopping_cnt = 0\n",
    "        else:\n",
    "            early_stopping_cnt += 1\n",
    "        \n",
    "        if early_stopping_cnt == CFG.early_stopping_rounds:\n",
    "            print(\"INFO : Early Stopped ! (Epoch[{0}/{1}])\".format(epoch+1, CFG.epochs))\n",
    "            break\n",
    "\n",
    "    torch.save(\n",
    "        model_save_dic,\n",
    "        f\"./model_fold{fold}_best.pth\",\n",
    "    )\n",
    "    score_list.append(return_score_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b96373-bc12-45b5-ba9c-15e46aee38f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda\\envs\\recom\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/70]\n",
      " train loss : 0.71534\n",
      " valid loss : 0.73259\n",
      " train accuracy : 0.50356\n",
      " valid accuracy : 0.49989\n",
      " eta : 0.0005\n",
      " Elapsed : 26.009\n",
      "\n",
      "Epoch[2/70]\n",
      " train loss : 0.71212\n",
      " valid loss : 0.72963\n",
      " train accuracy : 0.50412\n",
      " valid accuracy : 0.50015\n",
      " eta : 0.00049\n",
      " Elapsed : 25.059\n",
      "\n",
      "Epoch[3/70]\n",
      " train loss : 0.70931\n",
      " valid loss : 0.72707\n",
      " train accuracy : 0.50481\n",
      " valid accuracy : 0.50013\n",
      " eta : 0.00049\n",
      " Elapsed : 24.81\n",
      "\n",
      "Epoch[4/70]\n",
      " train loss : 0.70652\n",
      " valid loss : 0.7245\n",
      " train accuracy : 0.50551\n",
      " valid accuracy : 0.50022\n",
      " eta : 0.00049\n",
      " Elapsed : 24.581\n",
      "\n",
      "Epoch[5/70]\n",
      " train loss : 0.70401\n",
      " valid loss : 0.72216\n",
      " train accuracy : 0.50629\n",
      " valid accuracy : 0.5004\n",
      " eta : 0.00048\n",
      " Elapsed : 24.641\n",
      "\n",
      "Epoch[6/70]\n",
      " train loss : 0.70169\n",
      " valid loss : 0.7204\n",
      " train accuracy : 0.50712\n",
      " valid accuracy : 0.50056\n",
      " eta : 0.00048\n",
      " Elapsed : 24.541\n",
      "\n",
      "Epoch[7/70]\n",
      " train loss : 0.69956\n",
      " valid loss : 0.7183\n",
      " train accuracy : 0.50809\n",
      " valid accuracy : 0.50071\n",
      " eta : 0.00047\n",
      " Elapsed : 24.771\n",
      "\n",
      "Epoch[8/70]\n",
      " train loss : 0.6976\n",
      " valid loss : 0.71658\n",
      " train accuracy : 0.509\n",
      " valid accuracy : 0.50098\n",
      " eta : 0.00047\n",
      " Elapsed : 24.506\n",
      "\n",
      "Epoch[9/70]\n",
      " train loss : 0.69569\n",
      " valid loss : 0.71517\n",
      " train accuracy : 0.51002\n",
      " valid accuracy : 0.50123\n",
      " eta : 0.00047\n",
      " Elapsed : 24.524\n",
      "\n",
      "Epoch[10/70]\n",
      " train loss : 0.69404\n",
      " valid loss : 0.71389\n",
      " train accuracy : 0.5111\n",
      " valid accuracy : 0.50114\n",
      " eta : 0.00046\n",
      " Elapsed : 24.583\n",
      "\n",
      "Epoch[11/70]\n",
      " train loss : 0.69251\n",
      " valid loss : 0.7124\n",
      " train accuracy : 0.51224\n",
      " valid accuracy : 0.50143\n",
      " eta : 0.00046\n",
      " Elapsed : 24.488\n",
      "\n",
      "Epoch[12/70]\n",
      " train loss : 0.69109\n",
      " valid loss : 0.71136\n",
      " train accuracy : 0.51341\n",
      " valid accuracy : 0.50137\n",
      " eta : 0.00046\n",
      " Elapsed : 24.434\n",
      "\n",
      "Epoch[13/70]\n",
      " train loss : 0.68976\n",
      " valid loss : 0.7103\n",
      " train accuracy : 0.51458\n",
      " valid accuracy : 0.50181\n",
      " eta : 0.00045\n",
      " Elapsed : 24.398\n",
      "\n",
      "Epoch[14/70]\n",
      " train loss : 0.68853\n",
      " valid loss : 0.70922\n",
      " train accuracy : 0.51587\n",
      " valid accuracy : 0.50209\n",
      " eta : 0.00045\n",
      " Elapsed : 24.383\n",
      "\n",
      "Epoch[15/70]\n",
      " train loss : 0.68746\n",
      " valid loss : 0.70822\n",
      " train accuracy : 0.51701\n",
      " valid accuracy : 0.50246\n",
      " eta : 0.00044\n",
      " Elapsed : 24.501\n",
      "\n",
      "Epoch[16/70]\n",
      " train loss : 0.68637\n",
      " valid loss : 0.70761\n",
      " train accuracy : 0.51833\n",
      " valid accuracy : 0.50257\n",
      " eta : 0.00044\n",
      " Elapsed : 24.42\n",
      "\n",
      "Epoch[17/70]\n",
      " train loss : 0.6854\n",
      " valid loss : 0.70689\n",
      " train accuracy : 0.51964\n",
      " valid accuracy : 0.50282\n",
      " eta : 0.00044\n",
      " Elapsed : 24.341\n",
      "\n",
      "Epoch[18/70]\n",
      " train loss : 0.68452\n",
      " valid loss : 0.70617\n",
      " train accuracy : 0.52089\n",
      " valid accuracy : 0.50313\n",
      " eta : 0.00043\n",
      " Elapsed : 24.216\n",
      "\n",
      "Epoch[19/70]\n",
      " train loss : 0.68373\n",
      " valid loss : 0.70556\n",
      " train accuracy : 0.52212\n",
      " valid accuracy : 0.50354\n",
      " eta : 0.00043\n",
      " Elapsed : 24.248\n",
      "\n",
      "Epoch[20/70]\n",
      " train loss : 0.68299\n",
      " valid loss : 0.70518\n",
      " train accuracy : 0.52334\n",
      " valid accuracy : 0.50322\n",
      " eta : 0.00042\n",
      " Elapsed : 24.316\n",
      "\n",
      "Epoch[21/70]\n",
      " train loss : 0.68225\n",
      " valid loss : 0.70468\n",
      " train accuracy : 0.52463\n",
      " valid accuracy : 0.50382\n",
      " eta : 0.00042\n",
      " Elapsed : 24.468\n",
      "\n",
      "Epoch[22/70]\n",
      " train loss : 0.6816\n",
      " valid loss : 0.70402\n",
      " train accuracy : 0.52589\n",
      " valid accuracy : 0.50413\n",
      " eta : 0.00041\n",
      " Elapsed : 24.327\n",
      "\n",
      "Epoch[23/70]\n",
      " train loss : 0.68094\n",
      " valid loss : 0.70359\n",
      " train accuracy : 0.52717\n",
      " valid accuracy : 0.50434\n",
      " eta : 0.00041\n",
      " Elapsed : 24.557\n",
      "\n",
      "Epoch[24/70]\n",
      " train loss : 0.68047\n",
      " valid loss : 0.70328\n",
      " train accuracy : 0.52838\n",
      " valid accuracy : 0.50452\n",
      " eta : 0.00041\n",
      " Elapsed : 24.312\n",
      "\n",
      "Epoch[25/70]\n",
      " train loss : 0.67981\n",
      " valid loss : 0.70297\n",
      " train accuracy : 0.52954\n",
      " valid accuracy : 0.50488\n",
      " eta : 0.0004\n",
      " Elapsed : 24.491\n",
      "\n",
      "Epoch[26/70]\n",
      " train loss : 0.67934\n",
      " valid loss : 0.70265\n",
      " train accuracy : 0.53085\n",
      " valid accuracy : 0.50542\n",
      " eta : 0.0004\n",
      " Elapsed : 24.239\n",
      "\n",
      "Epoch[27/70]\n",
      " train loss : 0.67886\n",
      " valid loss : 0.70237\n",
      " train accuracy : 0.5319\n",
      " valid accuracy : 0.50548\n",
      " eta : 0.00039\n",
      " Elapsed : 24.254\n",
      "\n",
      "Epoch[28/70]\n",
      " train loss : 0.67844\n",
      " valid loss : 0.70203\n",
      " train accuracy : 0.53302\n",
      " valid accuracy : 0.5058\n",
      " eta : 0.00039\n",
      " Elapsed : 24.239\n",
      "\n",
      "Epoch[29/70]\n",
      " train loss : 0.67805\n",
      " valid loss : 0.70187\n",
      " train accuracy : 0.53402\n",
      " valid accuracy : 0.50601\n",
      " eta : 0.00038\n",
      " Elapsed : 24.242\n",
      "\n",
      "Epoch[30/70]\n",
      " train loss : 0.67762\n",
      " valid loss : 0.7017\n",
      " train accuracy : 0.53533\n",
      " valid accuracy : 0.5062\n",
      " eta : 0.00038\n",
      " Elapsed : 24.242\n",
      "\n",
      "Epoch[31/70]\n",
      " train loss : 0.67727\n",
      " valid loss : 0.70152\n",
      " train accuracy : 0.53608\n",
      " valid accuracy : 0.50608\n",
      " eta : 0.00037\n",
      " Elapsed : 24.252\n",
      "\n",
      "Epoch[32/70]\n",
      " train loss : 0.67693\n",
      " valid loss : 0.70126\n",
      " train accuracy : 0.53726\n",
      " valid accuracy : 0.50658\n",
      " eta : 0.00037\n",
      " Elapsed : 24.251\n",
      "\n",
      "Epoch[33/70]\n",
      " train loss : 0.6766\n",
      " valid loss : 0.70111\n",
      " train accuracy : 0.53818\n",
      " valid accuracy : 0.50664\n",
      " eta : 0.00036\n",
      " Elapsed : 24.257\n",
      "\n",
      "Epoch[34/70]\n",
      " train loss : 0.67625\n",
      " valid loss : 0.70087\n",
      " train accuracy : 0.53917\n",
      " valid accuracy : 0.5073\n",
      " eta : 0.00036\n",
      " Elapsed : 24.25\n",
      "\n",
      "Epoch[35/70]\n",
      " train loss : 0.676\n",
      " valid loss : 0.70075\n",
      " train accuracy : 0.54006\n",
      " valid accuracy : 0.50739\n",
      " eta : 0.00035\n",
      " Elapsed : 24.226\n",
      "\n",
      "Epoch[36/70]\n",
      " train loss : 0.67569\n",
      " valid loss : 0.70064\n",
      " train accuracy : 0.54096\n",
      " valid accuracy : 0.50756\n",
      " eta : 0.00035\n",
      " Elapsed : 24.832\n",
      "\n",
      "Epoch[37/70]\n",
      " train loss : 0.67539\n",
      " valid loss : 0.70067\n",
      " train accuracy : 0.54185\n",
      " valid accuracy : 0.50752\n",
      " eta : 0.00034\n",
      " Elapsed : 24.302\n",
      "\n",
      "Epoch[38/70]\n",
      " train loss : 0.67514\n",
      " valid loss : 0.70044\n",
      " train accuracy : 0.54272\n",
      " valid accuracy : 0.5077\n",
      " eta : 0.00034\n",
      " Elapsed : 24.303\n",
      "\n",
      "Epoch[39/70]\n",
      " train loss : 0.67494\n",
      " valid loss : 0.70033\n",
      " train accuracy : 0.54351\n",
      " valid accuracy : 0.50797\n",
      " eta : 0.00033\n",
      " Elapsed : 24.474\n",
      "\n",
      "Epoch[40/70]\n",
      " train loss : 0.6747\n",
      " valid loss : 0.70036\n",
      " train accuracy : 0.54427\n",
      " valid accuracy : 0.50798\n",
      " eta : 0.00033\n",
      " Elapsed : 24.433\n",
      "\n",
      "Epoch[41/70]\n",
      " train loss : 0.67443\n",
      " valid loss : 0.70015\n",
      " train accuracy : 0.54512\n",
      " valid accuracy : 0.50828\n",
      " eta : 0.00032\n",
      " Elapsed : 24.301\n",
      "\n",
      "Epoch[42/70]\n",
      " train loss : 0.67422\n",
      " valid loss : 0.70003\n",
      " train accuracy : 0.54581\n",
      " valid accuracy : 0.5086\n",
      " eta : 0.00032\n",
      " Elapsed : 24.414\n",
      "\n",
      "Epoch[43/70]\n",
      " train loss : 0.67403\n",
      " valid loss : 0.70002\n",
      " train accuracy : 0.54658\n",
      " valid accuracy : 0.5088\n",
      " eta : 0.00031\n",
      " Elapsed : 24.109\n",
      "\n",
      "Epoch[44/70]\n",
      " train loss : 0.67381\n",
      " valid loss : 0.70006\n",
      " train accuracy : 0.54713\n",
      " valid accuracy : 0.5089\n",
      " eta : 0.0003\n",
      " Elapsed : 24.262\n",
      "\n",
      "Epoch[45/70]\n",
      " train loss : 0.67363\n",
      " valid loss : 0.70006\n",
      " train accuracy : 0.54784\n",
      " valid accuracy : 0.50912\n",
      " eta : 0.0003\n",
      " Elapsed : 24.215\n",
      "\n",
      "Epoch[46/70]\n",
      " train loss : 0.67346\n",
      " valid loss : 0.69986\n",
      " train accuracy : 0.54834\n",
      " valid accuracy : 0.5094\n",
      " eta : 0.00029\n",
      " Elapsed : 24.28\n",
      "\n",
      "Epoch[47/70]\n",
      " train loss : 0.67328\n",
      " valid loss : 0.69988\n",
      " train accuracy : 0.54895\n",
      " valid accuracy : 0.50966\n",
      " eta : 0.00029\n",
      " Elapsed : 24.33\n",
      "\n",
      "Epoch[48/70]\n",
      " train loss : 0.67313\n",
      " valid loss : 0.69983\n",
      " train accuracy : 0.54945\n",
      " valid accuracy : 0.50986\n",
      " eta : 0.00028\n",
      " Elapsed : 24.277\n",
      "\n",
      "Epoch[49/70]\n",
      " train loss : 0.67286\n",
      " valid loss : 0.69988\n",
      " train accuracy : 0.55032\n",
      " valid accuracy : 0.50945\n",
      " eta : 0.00027\n",
      " Elapsed : 25.056\n",
      "\n",
      "Epoch[50/70]\n",
      " train loss : 0.67277\n",
      " valid loss : 0.69982\n",
      " train accuracy : 0.55076\n",
      " valid accuracy : 0.50951\n",
      " eta : 0.00027\n",
      " Elapsed : 25.062\n",
      "\n",
      "Epoch[51/70]\n",
      " train loss : 0.67264\n",
      " valid loss : 0.69969\n",
      " train accuracy : 0.55115\n",
      " valid accuracy : 0.50993\n",
      " eta : 0.00026\n",
      " Elapsed : 25.243\n",
      "\n",
      "Epoch[52/70]\n",
      " train loss : 0.67248\n",
      " valid loss : 0.6998\n",
      " train accuracy : 0.55174\n",
      " valid accuracy : 0.50986\n",
      " eta : 0.00025\n",
      " Elapsed : 25.095\n",
      "\n",
      "Epoch[53/70]\n",
      " train loss : 0.67231\n",
      " valid loss : 0.69958\n",
      " train accuracy : 0.55237\n",
      " valid accuracy : 0.51005\n",
      " eta : 0.00025\n",
      " Elapsed : 25.291\n",
      "\n",
      "Epoch[54/70]\n",
      " train loss : 0.6722\n",
      " valid loss : 0.69968\n",
      " train accuracy : 0.55269\n",
      " valid accuracy : 0.51016\n",
      " eta : 0.00024\n",
      " Elapsed : 24.588\n",
      "\n",
      "Epoch[55/70]\n",
      " train loss : 0.67207\n",
      " valid loss : 0.69972\n",
      " train accuracy : 0.55303\n",
      " valid accuracy : 0.50998\n",
      " eta : 0.00023\n",
      " Elapsed : 24.216\n",
      "\n",
      "Epoch[56/70]\n",
      " train loss : 0.67196\n",
      " valid loss : 0.69973\n",
      " train accuracy : 0.55364\n",
      " valid accuracy : 0.51015\n",
      " eta : 0.00022\n",
      " Elapsed : 24.191\n",
      "\n",
      "Epoch[57/70]\n",
      " train loss : 0.67182\n",
      " valid loss : 0.69977\n",
      " train accuracy : 0.55392\n",
      " valid accuracy : 0.51015\n",
      " eta : 0.00022\n",
      " Elapsed : 24.222\n",
      "\n",
      "Epoch[58/70]\n",
      " train loss : 0.67172\n",
      " valid loss : 0.69968\n",
      " train accuracy : 0.55448\n",
      " valid accuracy : 0.51044\n",
      " eta : 0.00021\n",
      " Elapsed : 24.205\n",
      "\n",
      "Epoch[59/70]\n",
      " train loss : 0.67163\n",
      " valid loss : 0.69963\n",
      " train accuracy : 0.55486\n",
      " valid accuracy : 0.51046\n",
      " eta : 0.0002\n",
      " Elapsed : 24.231\n",
      "\n",
      "Epoch[60/70]\n",
      " train loss : 0.67153\n",
      " valid loss : 0.69963\n",
      " train accuracy : 0.55502\n",
      " valid accuracy : 0.5106\n",
      " eta : 0.00019\n",
      " Elapsed : 24.208\n",
      "\n",
      "Epoch[61/70]\n",
      " train loss : 0.6714\n",
      " valid loss : 0.69966\n",
      " train accuracy : 0.55558\n",
      " valid accuracy : 0.51045\n",
      " eta : 0.00018\n",
      " Elapsed : 24.211\n",
      "\n",
      "Epoch[62/70]\n",
      " train loss : 0.67133\n",
      " valid loss : 0.69968\n",
      " train accuracy : 0.55573\n",
      " valid accuracy : 0.51067\n",
      " eta : 0.00017\n",
      " Elapsed : 24.235\n",
      "\n",
      "Epoch[63/70]\n",
      " train loss : 0.67125\n",
      " valid loss : 0.69965\n",
      " train accuracy : 0.55604\n",
      " valid accuracy : 0.51055\n",
      " eta : 0.00016\n",
      " Elapsed : 24.213\n",
      "\n",
      "INFO : Early Stopped ! (Epoch[63/70])\n",
      "CPU times: total: 27min 21s\n",
      "Wall time: 25min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_list = []\n",
    "\n",
    "do_fold_training(0)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a22d3e8a-90a1-44d5-908a-c4af26c76c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fold': 0, 'train_loss': 0.6723130941390991, 'valid_loss': 0.6995790600776672, 'train_accuracy': 0.5523701906204224, 'valid_accuracy': 0.5100537538528442}\n"
     ]
    }
   ],
   "source": [
    "print(score_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f96320-b5dc-41ac-afc4-9af11abcdcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
